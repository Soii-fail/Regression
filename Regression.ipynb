{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1) What is Simple Linear Regression?\n",
        "\n",
        "It is a statistical method that models the relationship between a dependent variable and one independent variable using a straight-line equation,\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘š\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "Y=mX+c, where\n",
        "ğ‘š\n",
        "m is the slope and\n",
        "ğ‘\n",
        "c is the intercept."
      ],
      "metadata": {
        "id": "dC2asRsQZCSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Linearity, independence of errors, homoscedasticity (constant variance of errors), normality of residuals, and no multicollinearity (though only one predictor is involved)."
      ],
      "metadata": {
        "id": "EIwVi4zvZM1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)  What does the coefficient m represent in the equation Y=mX+c\n",
        "\n",
        "m represents the slope, indicating the rate of change in\n",
        "ğ‘Œ\n",
        "Y for a one-unit increase in\n",
        "ğ‘‹\n",
        "X. It determines the strength and direction of the relationship between variables."
      ],
      "metadata": {
        "id": "E8OnMVaNZT_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) What does the intercept c represent in the equation Y=mX+c\n",
        "\n",
        "c represents the value of\n",
        "ğ‘Œ\n",
        "Y when\n",
        "ğ‘‹\n",
        "X is zero. It is the starting point of the regression line on the Y-axis."
      ],
      "metadata": {
        "id": "xi9e3mQbSUE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) How do we calculate the slope m in Simple Linear Regression\n",
        "\n",
        "The formula for the slope \\( m \\) is:\n",
        "\n",
        "$$\n",
        "m = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}\n",
        "$$\n",
        "\n",
        "\n",
        "Where:  \n",
        "( X_i \\) and \\( Y_i \\) are individual data points  \n",
        "X bar and Y bar are the means of \\( X \\) and \\( Y \\)\n",
        "\n",
        "This determines the rate of change of \\( Y \\) concerning \\( X \\), ensuring the best-fitting line."
      ],
      "metadata": {
        "id": "pU3kfYzZSc98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) What is the purpose of the least squares method in Simple Linear Regression\n",
        "\n",
        "It minimizes the sum of squared differences between actual and predicted values, ensuring the best-fitting line that reduces error variance."
      ],
      "metadata": {
        "id": "uYhtHXoaUf8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) How is the coefficient of determination (RÂ²) interpreted in Simple Linear Regression\n",
        "\n",
        "It measures the proportion of variance in the dependent variable explained by the independent variable, ranging from 0 to 1. Higher values indicate better model fit."
      ],
      "metadata": {
        "id": "790hXh0SSmSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8)  What is Multiple Linear Regression\n",
        "\n",
        "It extends Simple Linear Regression by modeling the relationship between one dependent variable and multiple independent variables using\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "1\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        ".\n",
        ".\n",
        ".\n",
        "+\n",
        "ğ‘\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "â€‹\n",
        " +b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        " +...+b\n",
        "n\n",
        "â€‹\n",
        " X\n",
        "n\n",
        "â€‹\n",
        " ."
      ],
      "metadata": {
        "id": "nSNxgJtiTrjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) What is the main difference between Simple and Multiple Linear Regression\n",
        "\n",
        "Simple Linear Regression has one independent variable, while Multiple Linear Regression has two or more. Multiple Linear Regression captures more complex relationships."
      ],
      "metadata": {
        "id": "uYtgPr-1U1pk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) What are the key assumptions of Multiple Linear Regression\n",
        "\n",
        "Linearity, no multicollinearity, independence of errors, homoscedasticity, normal distribution of residuals, and no autocorrelation in residuals."
      ],
      "metadata": {
        "id": "BXwXbvKfU8di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11) What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model\n",
        "\n",
        "It occurs when the variance of errors is not constant across all levels of the independent variables, leading to unreliable coefficient estimates and inefficient predictions."
      ],
      "metadata": {
        "id": "w_WMO0iOVAy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12) How can you improve a Multiple Linear Regression model with high multicollinearity\n",
        "\n",
        "Use variance inflation factor (VIF) to detect multicollinearity, drop highly correlated predictors, apply principal component analysis (PCA), or use regularization techniques like Ridge or Lasso regression."
      ],
      "metadata": {
        "id": "CIXUrxG5VOGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13) What are some common techniques for transforming categorical variables for use in regression models\n",
        "\n",
        "One-hot encoding, label encoding, ordinal encoding, and target encoding help incorporate categorical variables into regression models."
      ],
      "metadata": {
        "id": "5haTf58CVS4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14) What is the role of interaction terms in Multiple Linear Regression\n",
        "\n",
        "Interaction terms capture the combined effect of two independent variables on the dependent variable, helping to model more complex relationships."
      ],
      "metadata": {
        "id": "510wSLDPVi8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15) How can the interpretation of intercept differ between Simple and Multiple Linear Regression\n",
        "\n",
        "In Simple Linear Regression, the intercept represents the expected\n",
        "ğ‘Œ\n",
        " when\n",
        "ğ‘‹\n",
        " is zero. In Multiple Linear Regression, it is the expected\n",
        "ğ‘Œ\n",
        " when all independent variables are zero."
      ],
      "metadata": {
        "id": "ckDVJoDLVnN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16) What is the significance of the slope in regression analysis, and how does it affect predictions.\n",
        "\n",
        "The slope indicates how much the dependent variable changes for a one-unit increase in an independent variable, directly influencing predictions."
      ],
      "metadata": {
        "id": "VaRRadXoV1af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17) What are the limitations of using RÂ² as a sole measure of model performance\n",
        "\n",
        "It doesnâ€™t indicate causation, ignores overfitting, and doesnâ€™t penalize adding unnecessary variables, making adjusted RÂ² a better metric."
      ],
      "metadata": {
        "id": "5nxGSSFNV7DG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18) How would you interpret a large standard error for a regression coefficient\n",
        "\n",
        "It suggests high variability in coefficient estimation, implying that the predictor may not be reliable or has weak explanatory power."
      ],
      "metadata": {
        "id": "C96pvhreWFdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19) What is polynomial regression\n",
        "\n",
        "It extends linear regression by adding polynomial terms to model nonlinear relationships, using an equation like\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        ".\n",
        ".\n",
        ".\n",
        "+\n",
        "ğ‘\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X+b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        " +...+b\n",
        "n\n",
        "â€‹\n",
        " X\n",
        "n\n",
        " ."
      ],
      "metadata": {
        "id": "BgzYlGy9WJ4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20) When is polynomial regression used\n",
        "\n",
        "It is used when the relationship between the dependent and independent variables is nonlinear, making linear regression insufficient."
      ],
      "metadata": {
        "id": "R8f4DIyLXUcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21) How does the intercept in a regression model provide context for the relationship between variables\n",
        "\n",
        "It provides the baseline value of the dependent variable when all independent variables are zero, offering context to predictions."
      ],
      "metadata": {
        "id": "oy_oFBX_Xcrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22) How can heteroscedasticity be identified in residual plots, and why is it important to address it\n",
        "\n",
        "Residual plots with a funnel shape or non-random spread indicate heteroscedasticity, which can distort coefficient estimates and prediction accuracy."
      ],
      "metadata": {
        "id": "zinYuIVOXinx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23) What does it mean if a Multiple Linear Regression model has a high RÂ² but low adjusted RÂ²\n",
        "\n",
        "It suggests that adding more predictors increases RÂ² without significantly improving model performance, indicating overfitting."
      ],
      "metadata": {
        "id": "S0jWITaXXlLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24) Why is it important to scale variables in Multiple Linear Regression\n",
        "\n",
        "Scaling ensures fair weight distribution across features, prevents certain variables from dominating the model, and improves performance in gradient-based algorithms."
      ],
      "metadata": {
        "id": "HwKbcKSZXubp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25) How does polynomial regression differ from linear regression\n",
        "\n",
        "Polynomial regression fits a curved relationship using higher-degree terms, while linear regression fits a straight-line relationship."
      ],
      "metadata": {
        "id": "w0av4ZvmXzhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26) What is the general equation for polynomial regression\n",
        "\n",
        "The general equation for polynomial regression is:\n",
        "\n",
        "$$\n",
        "Y = b_0 + b_1X + b_2X^2 + ... + b_nX^n\n",
        "$$\n",
        "\n",
        "Where:  \n",
        "- \\( n \\) determines the polynomial degree.  \n",
        "- \\( b_0, b_1, ..., b_n \\) are the regression coefficients.  \n",
        "\n",
        "This allows modeling non-linear relationships between \\( X \\) and \\( Y \\)."
      ],
      "metadata": {
        "id": "gdQOVRzzX5t3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27) Can polynomial regression be applied to multiple variables\n",
        "\n",
        "Yes, polynomial regression can be extended to multiple independent variables by including interaction and squared terms."
      ],
      "metadata": {
        "id": "PtspRg2dYtNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28) What are the limitations of polynomial regression\n",
        "\n",
        "Overfitting, sensitivity to outliers, complex interpretation, and difficulty in selecting the right polynomial degree."
      ],
      "metadata": {
        "id": "nKSKLP8kZsjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29) What methods can be used to evaluate model fit when selecting the degree of a polynomial\n",
        "\n",
        "Use adjusted R2, cross-validation, residual plots, mean squared error (MSE), and Akaike Information Criterion (AIC)."
      ],
      "metadata": {
        "id": "0RV0ZEozaIUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30) Why is visualization important in polynomial regression\n",
        "\n",
        "Helps detect overfitting, assess curve fitting, and understand the nature of the nonlinear relationship."
      ],
      "metadata": {
        "id": "z1GpiLUeaOzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31) How is polynomial regression implemented in Python?\n",
        "\n",
        "By using PolynomialFeatures from sklearn.preprocessing to generate polynomial terms, then applying LinearRegression to fit the model."
      ],
      "metadata": {
        "id": "QCffsJdDaTmG"
      }
    }
  ]
}